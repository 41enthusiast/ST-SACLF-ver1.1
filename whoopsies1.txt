/home2/txlx81/new_repos/mv_test1/lib/python3.8/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
wandb: Currently logged in as: mridulav. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.15.3
wandb: Run data is saved locally in ./wandb/run-20230525_145526-jm7nvzi6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-mountain-8
wandb: â­ï¸ View project at https://wandb.ai/mridulav/stclassifier
wandb: ğŸš€ View run at https://wandb.ai/mridulav/stclassifier/runs/jm7nvzi6
/home2/txlx81/new_repos/mv_test1/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python train_test.py ...
  rank_zero_warn(
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[rank: 0] Global seed set to 42
/home2/txlx81/new_repos/mv_test1/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home2/txlx81/new_repos/mv_test1/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home2/txlx81/new_repos/mv_test1/lib/python3.8/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python train_test.py ...
  rank_zero_warn(
You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type       | Params
-------------------------------------
0 | model | AttnResNet | 43.6 M
-------------------------------------
20.1 M    Trainable params
23.5 M    Non-trainable params
43.6 M    Total params
174.355   Total estimated model params size (MB)
/home2/txlx81/new_repos/mv_test1/lib/python3.8/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
`Trainer.fit` stopped: `max_epochs=20` reached.
/home2/txlx81/new_repos/mv_test1/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home2/txlx81/new_repos/mv_test1/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:               epoch â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:             lr-Adam â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–
wandb:       test_accuracy â–
wandb:             test_f1 â–
wandb:           test_loss â–
wandb:      test_precision â–
wandb:         test_recall â–
wandb:     train_acc_epoch â–â–„â–…â–…â–…â–†â–†â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:      train_acc_step â–â–ƒâ–†â–„â–…â–†â–„â–‡â–†â–‡â–…â–…â–‡â–‡â–ˆâ–‡â–†â–‡â–‡â–‡â–‡â–†â–†â–†â–ˆâ–‡â–‡â–†â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–„â–…â–†â–†â–†â–‡
wandb:    train_loss_epoch â–ˆâ–…â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–
wandb:     train_loss_step â–ˆâ–†â–ƒâ–ƒâ–„â–ƒâ–…â–ƒâ–‚â–ƒâ–…â–„â–ƒâ–„â–â–ƒâ–‚â–‚â–â–â–‚â–‚â–â–‚â–â–‚â–â–ƒâ–â–â–â–‚â–â–â–ƒâ–‚â–ƒâ–‚â–‚â–‚
wandb: trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:             val_acc â–â–„â–…â–…â–‡â–†â–‡â–„â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:        val_accuracy â–â–„â–…â–…â–‡â–†â–‡â–„â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:              val_f1 â–â–ƒâ–„â–‡â–‡â–…â–‡â–…â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆ
wandb:            val_loss â–ˆâ–…â–„â–„â–‚â–‚â–‚â–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–
wandb:       val_precision â–â–ƒâ–ƒâ–‡â–„â–„â–‡â–†â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:          val_recall â–â–ƒâ–„â–†â–‡â–…â–‡â–…â–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:               epoch 20
wandb:             lr-Adam 1e-05
wandb:       test_accuracy 0.80947
wandb:             test_f1 0.13237
wandb:           test_loss 0.64898
wandb:      test_precision 0.15183
wandb:         test_recall 0.12413
wandb:     train_acc_epoch 0.89029
wandb:      train_acc_step 0.90625
wandb:    train_loss_epoch 0.25777
wandb:     train_loss_step 0.3114
wandb: trainer/global_step 6540
wandb:             val_acc 0.8071
wandb:        val_accuracy 0.8071
wandb:              val_f1 0.12656
wandb:            val_loss 0.5311
wandb:       val_precision 0.14203
wandb:          val_recall 0.11845
wandb: 
wandb: ğŸš€ View run worldly-mountain-8 at: https://wandb.ai/mridulav/stclassifier/runs/jm7nvzi6
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230525_145526-jm7nvzi6/logs
